{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ex 08 - Classification (Ensemble Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19.04.2023, Lukas Kretschmar (lukas.kretschmar@ost.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's have some Fun with Random Forests and Parameter Optimization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we're having a look at some advanced methods in classification and in general for Data Science.\n",
    "Concrete, we'll introduce the concept of **bagging** and **random forests** (multiple decision trees).\n",
    "And you'll get to know an approach how you can find good values for the **hyperparameters** of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous exercises, we run into several problems.\n",
    "We encountered problems with *overfitting* (classifier is too perfectly trained to predict the training set) and that some features have a huge impact on the result (and therefore might point into the wrong direction).\n",
    "And we know that using slightly different training data will result in different classifier models.\n",
    "Usually, the results will vary to some degree, but shouldn't be that far apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These problems or differences are mainly there because we only use one model that is trained once with a specific training set.\n",
    "A solution to mitigate these effects is called *ensemble method*.\n",
    "And it basically means, we take many classifiers that are trained on a subset of all the data and features.\n",
    "And the resulting class for a new data point is the class a majority of all these models return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This apprach is called *bagging*, and if we use bagging with decision trees, the classifier is called *random forest* (I mean, obviously many trees in the same area are called a forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, we tried to predict the price ranges for mobile phones based on their specs.\n",
    "And with a simple decision tree classifier we got an accuracy of 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"./Demo_MobilePhones.csv\", sep=\";\")\n",
    "labels = [\"low\", \"medium\", \"high\", \"very high\"]\n",
    "features = data.columns.drop(\"price_range\")\n",
    "\n",
    "X = data.drop(\"price_range\", axis=1)\n",
    "y = data[\"price_range\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.8, random_state=42)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, we also used pruning to increase the accuracy.\n",
    "But here, we ignore pruning and go with the default values of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can increase the accuracy from above.\n",
    "A general, bagging classifier can be loaded from the `ensemble` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the application is the same as with every other classifier you saw.\n",
    "There exists a `fit()` and `predict()` method that we can use.\n",
    "As you can see, the first argument of the `BaggingClassifier` is the model that should be used within the `BaggingClassifier`.\n",
    "It is also possible to parameterize the used classifier (here a `DecisionTreeClassifier`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(submodel, n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we combined bagging with decision trees.\n",
    "`n_estimators = 100` means that we trained 100 different trees.\n",
    "And as you can see, the classifier performs significantly better than just the one decision tree from the beginning.\n",
    "\n",
    "Let's see if we can do even better.\n",
    "We can limit the training data for every tree to 80% by setting `max_samples=.8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = DecisionTreeClassifier()\n",
    "model = BaggingClassifier(submodel, n_estimators=100, max_samples=.8, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we increased the accuracy again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw above, the `BaggingClassifier` comes with its own set of hyperparameters.\n",
    "We used `n_estimators` and `max_samples`.\n",
    "Another interesting hyperparameter is `max_features`.\n",
    "With this one, we can specify how many features should be used per tree.\n",
    "This can further increase the accuracy of the ensemble method since every model has its own training set with a subset of all features.\n",
    "\n",
    "In the next example, we'll use 80% of all features.\n",
    "And we get into the same range of accuracy as we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Number of features: {len(features)} --> 80% => {int(len(features)*.8)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(submodel, n_estimators=100, max_features=.8, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the combination of bagging and a decision tree classifier is common, there is a specific classifier for that.\n",
    "And the `RandomForestClassifier` comes with its own set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disassemble the Forst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both, the `BaggingClassifier` and `RandomForestClassifier`, allow you to access the models that were trained and used for the prediction by calling the `estimators_` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.estimators_))\n",
    "model.estimators_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can plot them with the same method you used in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = model.estimators_\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(20, 20))\n",
    "plot_tree(models[0], ax=ax[0,0], filled=True, rounded=True, feature_names=features, class_names=labels, max_depth=2, fontsize=10)\n",
    "ax[0,0].set(title=\"Estimator #1\")\n",
    "# We can create a dictionary holding all the styling parameters\n",
    "tree_style = {\"filled\":True, \"rounded\":True, \"feature_names\":features, \"class_names\":labels, \"max_depth\":2, \"fontsize\":10}\n",
    "# And use it as an argument at the end of the method\n",
    "plot_tree(models[32], ax=ax[0,1], **tree_style)\n",
    "ax[0,1].set(title=\"Estimator #33\")\n",
    "plot_tree(models[65], ax=ax[1,0], **tree_style)\n",
    "ax[1,0].set(title=\"Estimator #66\")\n",
    "plot_tree(models[99], ax=ax[1,1], **tree_style)\n",
    "ax[1,1].set(title=\"Estimator #100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic on finding the values for hyperparameters is a science for itself.\n",
    "Within these exercises, we get already good results with the default values.\n",
    "And we can simply test some combinations by hand, or with `for`-loops.\n",
    "\n",
    "But depending on the data we have, the model we want to use and the accuracy of the default values, it might be necessary to automate the process of finding good values for the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple solution is the scikit-learn [grid search algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) that tries all possible combinations for a given set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm offers many parameters that we can use to configure its execution.\n",
    "But most interesting for use are:\n",
    "- `estimator`: The model we want to find good hyperparameter values for.\n",
    "- `param_grid`: A dictionary containing the hyperparameters we want to test and their ranges.\n",
    "- `cv` (optional): The number of cross validation checks the algorithm should run.\n",
    "- `n_jobs` (option): Number of parallel executions. Default is `1`, `-1` means as many as possible (= 100% CPU usage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a grid search for the given problem.\n",
    "We want to limit the number of features checked (`max_features`), the depth (`max_depth`) and how long splits are allowed (`min_samples_split`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_features\": [12, 16, \"auto\", None],   # 12, 16, auto (sqrt) or all features\n",
    "    \"max_depth\": [4, None],                   # 4 levels, or full depth\n",
    "    \"min_samples_split\": [2, 10, 18]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preparation for the grid search algorithm looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "grid = GridSearchCV(submodel, params, cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to run the algorithm, we call the `fit()` method.\n",
    "Depending on the number of hyperparameters we test, and their ranges, the execution can take a while.\n",
    "Thus, the usage of `n_jobs` could be a wise choice.\n",
    "\n",
    "*Note:* Since the algorithm uses cross validation internally, we can use the whole dataset (`X`) and not just the training set (`X_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the algorithm is finished, we can get the best combination by calling the `best_params_` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation score for the best model can be found in the `best_score_` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can even get a configured model by calling the `best_estimator_` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we were able to increase the accuracy of our classifier.\n",
    "And with other parameters or broader ranges, further improvements might still be possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01 - Home Loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, you trained a classifier to suggest if a person is eligible for a loan.\n",
    "And you reached an accuracy of 74%.\n",
    "\n",
    "Now you'll do the same classification again, but this time you'll use a `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file **Ex08_01_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems identified in the last exercise was that the decision tree basically denied loans for every new customer.\n",
    "Thus, let's see if we have a problem with class imbalance.\n",
    "To do so, count the values in `LoanStatus` and show them in a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, class imbalance is probably an issue within this dataset.\n",
    "Thus, build a new dataset that takes all the accepted applications (`LoanStatus==1`) and add 400 entries of denied loan applications (`LoanStatus==0`).\n",
    "And plot the bar chart again.\n",
    "\n",
    "*Hint:* `sample()` (Ex04) and `pd.concat()` (Ex02) may become handy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a train set with 80% of the resampled data.\n",
    "And don't forget to drop the `Loan_ID` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variables containing the labels and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your `RandomForestClassifier` and train it.\n",
    "Use 100 internal trees and `min_samples_split=24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the classes and show the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new classifier, you were able to increase the accuracy by some percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrix for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, draw the top 3 levels of 6 decision trees in a 2x3 grid (like in the introduction).\n",
    "You are free to choose which 6 trees you want to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex08_01_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02 - Marketing Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you are going to analyse marketing data of a bank.\n",
    "The goal is to predict whether a customer will open a deposit account or not if targeted by a campaign (`campaign_success`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the data from **Ex08_02_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a problem with class imbalance.\n",
    "Plot a bar chart for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a massive difference between data on failed campaigns compared to successful calls.\n",
    "Thus, you need to upsample the successful cases.\n",
    "Generate 35000 successful data points from the existing ones, take all the failed cases and show that the class imbalance is gone in your new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the labels and features collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your train (80%) and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your `RandomForestClassifier` using 100 trees and 80% of the samples per tree.\n",
    "What's the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!\n",
    "Over 95% - great work.\n",
    "Show the confusion matrix to see where the errors are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks quite good.\n",
    "Thus, create a new model (with the same hyperparameters used above) and train it on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load another dataset (**Ex08_02_Data_Use.csv**) that has no information on the campaign success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the probabilities of a campaigns success for these new data points.\n",
    "Use the `predict_proba()` method and add the new columns to the beginning of the dataset.\n",
    "The column containing the success probability should be the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to not lose time, sort the data points by their expected success with the most likely customer to sign up for a new account on top of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work!\n",
    "Your job is done.\n",
    "Now you can send the sheet to your marketing department, it's now their job to reach out to these customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex08_02_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex03 - eCommerce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you run an eCommerce business.\n",
    "And you want to know when people buy something from your website.\n",
    "\n",
    "For every visitor on your site, you log certain information (e.g. which pages were visited, how long was the visitor on a page, when was that, did you already know the visitor, etc).\n",
    "Based on this information, you'll try to estimate if the visitor will actually order something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is logged in **Ex08_03_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Revenue` column is what you want to know.\n",
    "But before you can go on, check for class imbalance.\n",
    "Show it with a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you have to fix this problem first.\n",
    "Generate 10'000 data points where a visitor actually ordered something, and combine them with all the data points where the visitor left without any purchase.\n",
    "Show the result again as bar chart to be sure the class imbalance is gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset containing the features and the series containing the `Revenue` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of just training one `RandomForestClassifier`, do a grid search with:\n",
    "- `max_features`: `[8, 16, \"sqrt\", None]`\n",
    "- `max_samples`: `[.8, None]`\n",
    "- `min_samples_split`: `[2, 10, 18]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best combination of values for your hyperparameters? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the cross validation score of the best model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best model and train it with the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load **Ex08_03_Data_Use.csv**.\n",
    "This file contains new logs of visitors on your page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the probability that a visitor will buy something from you.\n",
    "And show the value in the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you've created a classifier that predicts if a visitor will buy something.\n",
    "Now you can optimize your website to increase the likelihood of a purchase for those who are likely to buy something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex08_03_Sol.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
