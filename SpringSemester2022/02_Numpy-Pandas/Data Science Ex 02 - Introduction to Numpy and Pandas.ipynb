{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ex 02 - Introduction to NumPy and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "02.03.2022, Lukas Kretschmar (lukas.kretschmar@ost.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have some Fun with Numbers and Tables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we are going to have a look at the basic modules and types you need to know to work with large sets of data.\n",
    "We are going to have a look at **NumPy** and **Pandas**, as well as how you can **load data** to start *number crunching*.\n",
    "Since we will constantly stumble acorss NumPy and Pandas, invest enough time to understand these modules and their features.\n",
    "Beginning next week, we will have some fun with visualizing data and begin with pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tab Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When modules were imported, depending on the module, they'll introduce an unknowable amount of types and functions.\n",
    "And we are certainly not able to remember everything.\n",
    "IPython offers a simple solution for this issue - *tab completion*.\n",
    "Just enter the module or type, add the *.* and then press *Tab*.\n",
    "\n",
    "```python\n",
    "math.<Tab>\n",
    "```\n",
    "\n",
    "A list of all available functions and fields is then shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://numpy.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NumPy* is the fundament of nearly all Data Science modules and approaches in Python.\n",
    "It offers special data types and functions that enable fast and easy manipulation of large datasets.\n",
    "But before we are going to dive deep into NumPy, we have to import the module.\n",
    "Using Anaconda, NumPy is already installed, thus we just have to import NumPy into our notebook.\n",
    "```python\n",
    "import numpy as np\n",
    "```\n",
    "Using `np` as alias is a common approach in the data science community, so we will stick with it, too.\n",
    "But you are free to use your own aliases or even leave it away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why NumPy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing is, as we have seen in the last exercise, Python offers much flexibility regarding data types.\n",
    "What takes away complexity from the developer, adds complexity to the internal structures.\n",
    "But complexity has a negative impact on performance.\n",
    "And the last thing we want when manipulating huge datasets, is waiting on the results.\n",
    "\n",
    "Thus, a new solution had to be developed.\n",
    "And it's called **NumPy**.\n",
    "NumPy introduces new basic data types (e.g. integers, floats, etc.) that are mapped upon `C` types.\n",
    "So, rather than introducing complexity, they are more or less simple wrappers.\n",
    "In this case, simplicity leads to faster code execution, and with large datasets this can safe you a significant amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "%timeit slow = [rnd.random() for _ in range(100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit fast = np.random.random(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the simple example above, we see that creating 100'000 random floating point numbers between 0 and 1 is more than an order of magnitude faster when using NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://numpy.org/doc/stable/user/basics.types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't go much into detail regarding the basic data types offered by NumPy.\n",
    "For an exhaustive overview, please check the link provided above.\n",
    "\n",
    "The most common types we will work with are the following:\n",
    "- np.bool (`True` or `False`)\n",
    "- np.int8 (-128 to 127)\n",
    "- np.int16 (-32'768 to 32'767)\n",
    "- np.int32 (-2'147'483'648 to 2'147'483'647) $\\leftarrow$ up to 2 Billion\n",
    "- np.int64 (-9'223'372'036'854'775'808 to 9'223'372'036'854'775'807) $\\leftarrow$ up to 9 Quintillion\n",
    "- np.float32 (floating point numbers)\n",
    "- np.float64 (double precision floating point numbers)\n",
    "\n",
    "Sometimes, it could also be interesting to work with unsigned integers.\n",
    "As you saw, integers have a range from - to + with 0 in the middle.\n",
    "But when we know that negative values are not possible, we could use unsigned values.\n",
    "They just shift the range to positive numbers, starting at 0.\n",
    "- np.uint8 (0 to 255)\n",
    "- np.uint16 (0 to 65'535)\n",
    "- np.uint32 (0 to 4'294'967'295)\n",
    "- np.uint64 (0 to 18'446'744'073'709'551'615)\n",
    "\n",
    "Most of the time, we are fine without using unsigned types, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dig deeper into NumPy, a word on random numbers.\n",
    "NumPy includes a random number generator, or RNG for short.\n",
    "The numbers we'll get back, are pseudo-random.\n",
    "This means, they look random, but are acutally calculated by an algorithm.\n",
    "\n",
    "If we do not take any action, everytime we generate numbers, they'll be different.\n",
    "But, since an algorithm is generating them, we can enforce reproducibility.\n",
    "This can be done in two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `np.random.seed(seed)`\n",
    "\n",
    "`seed` is an initial value taken for the random number generator.\n",
    "Using this method, we will set a global seed for the static RNG within NumPy.\n",
    "This means, if we call, for example, `np.random.random()`, the order of random numbers we get is always the same, if the order of calls stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "print(np.random.random(3))\n",
    "\n",
    "np.random.seed(42)\n",
    "print(np.random.random(3))\n",
    "print()\n",
    "\n",
    "np.random.seed(42)\n",
    "print(np.random.random())\n",
    "print(\"Now we have changed the order respectively the values are shifted by one\")\n",
    "print(np.random.random(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `rng = np.random.RandomState(42)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other approach, besides setting a global seed, or for that matter a global `RandomState()`, is to use a more object-oriented approach by creating instances of random number generators.\n",
    "This way, we can work with multiple random number generators that generate the same sequence of numbers or don't.\n",
    "But are not affected by calls done inbetween."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng1 = np.random.RandomState(42)\n",
    "rng2 = np.random.RandomState(42)\n",
    "rngOther = np.random.RandomState(1337)\n",
    "\n",
    "print(rng1.rand(3))\n",
    "print(rngOther.rand(3))\n",
    "print(rng2.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use both approaches during the exercises.\n",
    "But none is better than the other.\n",
    "It depends on the case you want to show, and your preference.\n",
    "We suggest for just showing examples, the first one is easier to apply.\n",
    "But when doing number crunching, the second one is more suitable, as it allows to control reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the basic data types, NumPy introduces its own implementation of an array.\n",
    "And basically everything in NumPy and Pandas is built upon this implementation.\n",
    "Thus, we will have a look at what you can do with arrays, and later on, what functions exist that take arrays as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an array from a list, with a given default value, evenly spaced or filled with random numbers (and many more possibilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromList = np.array([1,2,3,4,5])\n",
    "print(f\"fromList = {fromList}\")\n",
    "\n",
    "withZeros = np.zeros(5)\n",
    "print(f\"withZeros =  {withZeros}\")\n",
    "\n",
    "withOnes = np.ones(5)\n",
    "print(f\"withOnes = {withOnes}\")\n",
    "\n",
    "withDefaults = np.full(5, 42)\n",
    "print(f\"withDefaults = {withDefaults}\")\n",
    "\n",
    "withRange = np.arange(0, 10, 2) # np.array(range(0, 10, 2))\n",
    "print(f\"withRange = {withRange}\")\n",
    "\n",
    "withSpace = np.linspace(0, 1, 5)\n",
    "print(f\"withSpace = {withSpace}\")\n",
    "\n",
    "withRandom = np.random.random(5)\n",
    "print(f\"withRandom = {withRandom}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've done so far, is creating one-dimensional arrays.\n",
    "Every method used above could also be used to create multidimensional arrays by providing a tuple representing the size.\n",
    "The parameter `size` is defined as `(outermost dimension, ..., innermost dimension)`.\n",
    "You could understand this as `(further dimensions, ..., rows, columns)`.\n",
    "So, for an example, a 4x2 array is defined as `(4, 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emptyMatrix = np.zeros((3,3))\n",
    "print(emptyMatrix)\n",
    "print()\n",
    "\n",
    "allAnswers = np.full((4,2), 42)\n",
    "print(allAnswers)\n",
    "print()\n",
    "\n",
    "nDimRandoms = np.random.random(size=(2,3,4,5))\n",
    "print(nDimRandoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to get information about the structure of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dimensions: {nDimRandoms.ndim}\")\n",
    "print(f\"Shape: {nDimRandoms.shape}\")\n",
    "print(f\"Size: {nDimRandoms.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing values within an array is done the same way as with lists.\n",
    "We simply have to provide the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0,10)\n",
    "print(arr)\n",
    "\n",
    "print(arr[1])\n",
    "print(arr[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides index based access, we can also access ranges within an array by providing a colon `:` separated range.\n",
    "A range is defined as `start:stop:step`.\n",
    "The default values are\n",
    "- `start = 0`\n",
    "- `stop = size of dimension`\n",
    "- `step = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)\n",
    "print(\"#\" * 42)\n",
    "print()\n",
    "\n",
    "print(\"Selecting second to second last items:\")\n",
    "subArr = arr[1:8]\n",
    "print(subArr)\n",
    "print()\n",
    "\n",
    "print(\"Selecting the first two items:\")\n",
    "firstTwo = arr[:2]\n",
    "print(firstTwo)\n",
    "print()\n",
    "\n",
    "print(\"Selecting the last three items:\")\n",
    "lastThree = arr[-3:]\n",
    "print(lastThree)\n",
    "print()\n",
    "\n",
    "print(\"Selecting every other item:\")\n",
    "everyOther = arr[::2]\n",
    "print(everyOther)\n",
    "print()\n",
    "\n",
    "print(\"Reverse the array - this trick is quite handy!\")\n",
    "reverse = arr[::-1]\n",
    "print(reverse)\n",
    "print()\n",
    "\n",
    "# This is totally legit\n",
    "print(\"Using all the default values when selecting a range:\")\n",
    "theSame = arr[::]\n",
    "print(theSame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Sub-arrays, also called slices, are a view on the array, but not a copy.\n",
    "This means, when we change a value within the sub-array, the value gets changed in the original array, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrCopy = arr.copy() # This is how we make a copy of an array. We do this to not destroy our arr array used as an example.\n",
    "subArrCopy = arrCopy[2:5]\n",
    "\n",
    "print(f\"Original array: {arr}\")\n",
    "print(f\"Copy: {arrCopy}\")\n",
    "print(f\"Sub-array: {subArrCopy}\")\n",
    "\n",
    "subArrCopy[0] = 42\n",
    "\n",
    "print(f\"Changed to 42: {subArrCopy}\")\n",
    "print(f\"Changed copy: {arrCopy}\")\n",
    "print(f\"Original: {arr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous examples, we always had the dimensions of your arrays the way we needed them.\n",
    "Now, depending on the size we need, we have to change the shape of an array.\n",
    "This can be done by using the `reshape()` function that takes the new shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(1, 10).reshape((3,3))\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a really handy feature, when we have to swap between row-vectors and column-vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0,10)\n",
    "row = arr.reshape((1,10))\n",
    "print(row)\n",
    "column = arr.reshape((10,1))\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.newaxis` offers an alternative way to create row- and column-vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherRow = arr[np.newaxis,:]\n",
    "print(otherRow)\n",
    "otherColumn = arr[:,np.newaxis]\n",
    "print(otherColumn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UFunc (Universal Funcitons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have seen so far are functions that we can use to create and form arrays.\n",
    "Since arrays are such a central part of NumPy, the module also offers functions - so called **universal functions** - to manipulate arrays very efficiently.\n",
    "Every basic operator that you usually use, like `+, -, *, /, //, **, %`, can also be applied on arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(9).reshape((3,3))\n",
    "\n",
    "gridAdd = grid + 2\n",
    "print(gridAdd)\n",
    "print()\n",
    "\n",
    "gridSub = grid - 3\n",
    "print(gridSub)\n",
    "print()\n",
    "\n",
    "gridMul = grid * 2\n",
    "print(gridMul)\n",
    "print()\n",
    "\n",
    "gridDiv = grid / 3\n",
    "print(gridDiv)\n",
    "print()\n",
    "\n",
    "gridDivR = grid // 3\n",
    "print(gridDivR)\n",
    "print()\n",
    "\n",
    "gridSquare = grid ** 2\n",
    "print(gridSquare)\n",
    "print()\n",
    "\n",
    "gridMod = grid % 3\n",
    "print(gridMod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there is more.\n",
    "We can also use an array on the right hand side of an operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridReciproc = 1 / grid\n",
    "print(gridReciproc) # Division by 0 obviously won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use arrays on both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridMulEx = grid * np.arange(1,10).reshape((3,3))\n",
    "print(gridMulEx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And obviously, we can use all these operators together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (-grid * 2) + 5\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the background, all these operators have a corresponding function.\n",
    "Using `+` is the same as using `np.add()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resAdd1 = grid + 5\n",
    "resAdd2 = np.add(grid, 5)\n",
    "print(resAdd1)\n",
    "print()\n",
    "print(resAdd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leave it to you to find the other functions for the basic operators for when you need them.\n",
    "But here are some other ufuncs that are interesting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.abs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(-2,3)\n",
    "print(f\"{arr} -> {np.abs(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.exp()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0,3)\n",
    "print(f\"x   = {arr}\")\n",
    "print(f\"e^x = {np.exp(arr)}\")\n",
    "print(f\"2^x = {np.exp2(arr)}\")\n",
    "print(f\"4^x = {np.power(4, arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.log()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1,2,4,10])\n",
    "print(f\"x        = {arr}\")\n",
    "print(f\"ln(x)    = {np.log(arr)}\")\n",
    "print(f\"log2(x)  = {np.log2(arr)}\")\n",
    "print(f\"log10(x) = {np.log10(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.sin()`\n",
    "- `np.cos()`\n",
    "- `np.tan()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.linspace(0, np.pi, 3)\n",
    "print(f\"alpha      = {alpha}\")\n",
    "print(f\"sin(alpha) = {np.sin(alpha)}\")\n",
    "print(f\"cos(alpha) = {np.cos(alpha)}\")\n",
    "print(f\"tan(alpha) = {np.tan(alpha)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the values are calculated and depend on the machines precision, results that should be zero might not be exactly zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ufuncs, we can manipulate values within arrays at once.\n",
    "Another feature we need, is the ability to aggregate values of an array to one value (e.g. sum, max, min).\n",
    "NumPy also offers functions for these types of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.sum()`\n",
    "- `np.cumsum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,6)\n",
    "print(f\"{arr} = {np.sum(arr)}\")\n",
    "print(f\"{arr} = {np.cumsum(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.prod()`\n",
    "- `np.cumprod()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,6)\n",
    "print(f\"{arr} = {np.prod(arr)}\")\n",
    "print(f\"{arr} = {np.cumprod(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.min()`\n",
    "- `np.max()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(100, size=10)\n",
    "print(f\"min({arr}) = {np.min(arr)}\")\n",
    "print(f\"max({arr}) = {np.max(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.all()`\n",
    "- `np.any()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([False, True, False])\n",
    "print(f\"all({arr}) = {np.all(arr)}\")\n",
    "print(f\"any({arr}) = {np.any(arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.mean()`\n",
    "- `np.median()`\n",
    "- `np.var()`\n",
    "- `np.std()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.normal(size=1000000)\n",
    "print(f\"mean = {np.mean(arr)}\")\n",
    "print(f\"median = {np.median(arr)}\")\n",
    "print(f\"var = {np.var(arr)}\")\n",
    "print(f\"std = {np.std(arr)}\")\n",
    "print()\n",
    "print(\"Actual values should be:\")\n",
    "print(\"- mean = median = 0\")\n",
    "print(\"- var = std = 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to manipulate arrays at once is one thing, what we now want to use, is checking assumptions against arrays and compare arrays.\n",
    "Again, NumPy provides ufuncs and operators for that.\n",
    "\n",
    "**Please note:** This section is quite important as it shows and teaches you the basics on how to filter *DataFrames* in *Pandas* later in this notebook and course.\n",
    "So try to get and understand as much as possible here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,10)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr != 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr <= 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr >= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operators also work when you have arrays on both sides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(3)\n",
    "rra = np.arange(3)[::-1]\n",
    "print(arr)\n",
    "print(rra)\n",
    "print(\"#\" * 21)\n",
    "print(arr == rra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we have seen that an `np.all()` and `np.any()` ufunc exists.\n",
    "Knowing how to use comparisons enables new possibilities in combination with these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(0,10)\n",
    "print(np.all(arr < 10))\n",
    "print(np.any(arr > 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want some more detail, for example the number of values that are `True` or `False`, we can use `np.count_nonzero()` or even `np.sum()`.\n",
    "Because `True` counts as 1 and `False` as 0, `np.sum()` will return the number of `True` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(5,15)\n",
    "print(np.count_nonzero(arr < 10))\n",
    "print(np.sum(arr < 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen how to get arrays of booleans, we can go a step further and combine expressions.\n",
    "NumPy supports the follwing bitwise operators:\n",
    "- `&` and (both must be true)\n",
    "- `|` or (one must be true)\n",
    "- `^` xor (only one can be true)\n",
    "- `~` not (negate all values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolRow = np.array([True, False])\n",
    "boolCol = np.array([[True], [False]])\n",
    "print(boolRow)\n",
    "print(boolCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolRow & boolCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolRow | boolCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolRow ^ boolCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(~boolRow)\n",
    "print(~boolCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use this knowledge on bitwise comparison to define more complex expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "print((arr > 5) & (arr <= 7) | (arr == 0))\n",
    "print(np.sum((arr > 5) & (arr <= 7) | (arr == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note:** It is important that you always encapsulate the comparison with brackets `(...)`.\n",
    "Otherwise, the code cannot be executed.\n",
    "And I usually test this exact knowledge in the final exam.\n",
    "So consider yourself warned =).\n",
    "Anyway, let's move on. Shall we?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go even further, and use these arrays of booleans to get the values at their locations.\n",
    "Taking the example from above, we know that 3 values fulfill our requirement, but we want the values, and not just a sum.\n",
    "Easier done than said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[(arr > 5) & (arr <= 7) | (arr == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an array of booleans as index will return the values at every position where the array's value is `True`.\n",
    "And this is also how filtering in Pandas works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(3)\n",
    "print(arr) \n",
    "print(arr[[False, True, False]]) # Explicit array\n",
    "print(arr[arr == 1]) # Using the array of the comparison\n",
    "print(arr[~(arr == 1)]) # Using the negated comparison\n",
    "print(arr[arr != 1]) # The same as the line above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with arrays, it might be needed to sort them.\n",
    "NumPy offers two simple methods that we will use to get numbers in order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `np.sort(array)`\n",
    "\n",
    "This function simply sorts the array and returns the sorted values.\n",
    "The original array is not affected, but a new one is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0,10, 10)\n",
    "sorted = np.sort(arr)\n",
    "print(f\"{arr} --> {sorted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `np.argsort(array)`\n",
    "\n",
    "This function returns the indices in order rather than the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.randint(0, 10, 10)\n",
    "idx = np.argsort(arr)\n",
    "print(f\"{arr} --> {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing fancy indexing (see below in the *self-study* section), we can use this array again, to sort the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Broadcasting* is NumPys functionality to combine arrays of different size.\n",
    "We don't have to think much, but just use functions on arrays we expect to be valid.\n",
    "A simple example of broadcasting is adding a scalar.\n",
    "We could imagine that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0, 1, 2]) + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is the same as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([0, 1, 2]) + np.array([5, 5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is also true for the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = np.arange(3)\n",
    "column = np.arange(3)[:,np.newaxis]\n",
    "print(row)\n",
    "print(column)\n",
    "print()\n",
    "print(row + column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, NumPy behaves as we expect it when adding two arrays with different dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation & Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having worked with one array, it is also possible to combine (contactenate) or split multiple arrays.\n",
    "Concatenation is done by using the `np.concatenate()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.arange(0,5)\n",
    "arr2 = np.arange(10,15)\n",
    "arrC = np.concatenate([arr1, arr2])\n",
    "print(arrC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `np.concatenate()` also for multi dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrGrid = np.arange(1,10).reshape((3,3))\n",
    "arrGridC = np.concatenate([arrGrid, arrGrid])\n",
    "print(arrGridC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on number of dimensions we have, we can specify which `axis` should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrGridC = np.concatenate([arrGrid, arrGrid], axis=1)\n",
    "print(arrGridC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we are working with arrays of mixed dimensions, `np.vstack()` and `np.hstack()` come in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1d = np.arange(3)\n",
    "arr2d = np.arange(3,9).reshape((2,3))\n",
    "arrV = np.vstack([arr1d, arr2d])\n",
    "print(arrV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2dn = np.array([[10], [11]])\n",
    "arrH = np.hstack([arr2d, arr2dn])\n",
    "print(arrH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `np.split()`, `np.vsplit()` and `np.hsplit()` we can take arrays apart.\n",
    "Theses functions take an array of split points as argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(16)\n",
    "left, middle, right = np.split(arr, [4,12]) # Middle starts at index 4, right starts at index 12\n",
    "print(left, middle, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(16).reshape((4,4))\n",
    "upper, lower = np.vsplit(grid, [2])\n",
    "print(upper)\n",
    "print(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, right = np.hsplit(grid, [2])\n",
    "print(left)\n",
    "print(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fancy Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fancy Indexing* is just a fancy term in NumPy that you can access values in arrays the way you want.\n",
    "Upto now, we have seen the following ways to access values of an array:\n",
    "- By Index (e.g. `arr[4]`)\n",
    "- By Range (e.g. `arr[4:10:2]`)\n",
    "- By Comparison (e.g. `arr[arr > 5]`)\n",
    "- By Bool-array (e.g. `arr[[True, False, False]]`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there is one more way - by index-array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,16)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([2,3,4])\n",
    "arr[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the order of indices matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([12,5,8,0])\n",
    "arr[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even the dimensions of the index-array matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.array([[5,7], [3, 10]])\n",
    "arr[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even combine it with slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1, 17).reshape((4,4))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = np.array([1,3])\n",
    "arr[2:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array([0,2])\n",
    "arr[rows, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dimension Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi dimensional arrays take comma separated indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrN = np.random.randint(100, size=(2,3,4))\n",
    "print(arrN)\n",
    "print()\n",
    "\n",
    "# Second array, first row, last column\n",
    "print(arrN[1,0,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can slice multi dimensional arrays as well.\n",
    "A range is defined as `start:stop:step`.\n",
    "The default values are\n",
    "- `start = 0`\n",
    "- `stop = size of dimension`\n",
    "- `step = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arrN)\n",
    "print(\"#\" * 42)\n",
    "print()\n",
    "\n",
    "# Take both arrays, last two rows and columns in reverse but only every second value.\n",
    "subPart = arrN[::, 1:,::-2]\n",
    "print(subPart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-dimensional arrays can also be compared to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.arange(16).reshape((4,4))\n",
    "inner = np.full((4,4), -1)\n",
    "inner[1:3, 1:3] = np.array([[5,6], [9, 10]])\n",
    "\n",
    "print(grid)\n",
    "print()\n",
    "print(inner)\n",
    "print()\n",
    "print(grid == inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with multi dimensional arrays, `np.sum()` can be used for a specific dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(16).reshape((4,4))\n",
    "print(arr)\n",
    "print()\n",
    "print(f\"Values >= 10 per column: {np.sum(arr >= 10, axis=0)}\")\n",
    "print(f\"Values >= 10 per row: {np.sum(arr >= 10, axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, Pandas has nothing to do with the animal.\n",
    "Period.\n",
    "Although - it feels fluffy.\n",
    "Originally, it's derived from the term [panel data](https://en.wikipedia.org/wiki/Panel_data).\n",
    "\n",
    "*Pandas* is a module that builds upon NumPy, but provides functions to actually work with data.\n",
    "NumPy offers the basic structure - the array.\n",
    "And Pandas introduces new objects, using the array, but offering functions that we want to analyse and mutate data.\n",
    "\n",
    "But let's begin by importing the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we check out the awesome stuff, Pandas allows us to do.\n",
    "Let's have a look at the three fundamental structures Pandas provides.\n",
    "\n",
    "- `Series` $\\leftarrow$ \"Columns\"\n",
    "- `Index` $\\leftarrow$ \"First Column\"\n",
    "- `DataFrame` $\\leftarrow$ \"Tables\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/series.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Pandas `Series` is a one-dimensional array of indexed data.\n",
    "We can simply create one by throwing an array into the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the left column, you see the indices.\n",
    "In the right one, the values of the series are stored.\n",
    "We can even access these information by fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, slicing is also possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you think that a `Series` is nothing more but an array, let me show you something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5), index=[\"a\",\"b\",\"c\",\"d\",\"e\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5), index=range(100,110,2))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5), index=[7,42,1,364,0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, working with slicing here is a bit more trickier, but we will get to that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having indices that are not numbers, we can still use slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5), index=[\"a\",\"b\",\"c\",\"d\",\"e\"])\n",
    "data[\"b\":\"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it doesn't matter if the order of indices makes sense (is ordered somehow).\n",
    "Slicing is selecting top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5), index=[\"t\", \"y\", \"e\", \"x\", \"d\"])\n",
    "data[\"y\":\"d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a `Series` with a default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(42, index=range(0,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or based on a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series({\"a\": 42, \"b\": 1337, \"c\": 4.2})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or just take some values from the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series({\"a\": 42, \"b\": 1337, \"c\": 4.2}, index=[\"b\", \"a\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/indexing.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, `Series` contain an index.\n",
    "And this index has its own type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = pd.Series(np.random.randint(0,10,4))\n",
    "print(series.index)\n",
    "frame = pd.DataFrame([1,2,3], index=[\"a\", \"b\", \"c\"])\n",
    "print(frame.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply said, an index is an immutable array.\n",
    "*Immutable* means that you cannot change an instance's content.\n",
    "`Index` work like arrays (that you know from NumPy), but you cannot add, remove or change values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.Index([4,3,6,21,5])\n",
    "print(idx[1])\n",
    "print(idx[2:4])\n",
    "print(idx[::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, you don't have to build your own `Index` since it will be created within the `DataFrame`.\n",
    "But we will use their behavior as sets during the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having had some fun with `Series`, let's go a step further.\n",
    "The multi-dimensional part to the one-dimensional `Series`, is called a `DataFrame`.\n",
    "When creating a `DataFrame`, the indices simply have to match, so the constructor knows which entries belong together.\n",
    "We won't cover every possibility on how to construct a `DataFrame`.\n",
    "For more detail, please have a look at the link provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({\"Zurich\": 87.88, \"St.Gallen\": 39.41,\"Geneva\": 15.92,\"Rapperswil\": 1.74,\"Bern\": 51.62})\n",
    "population = pd.Series({\"Zurich\": 415215, \"St.Gallen\": 75806,\"Geneva\": 201741,\"Rapperswil\": 7601,\"Bern\": 133791})\n",
    "\n",
    "df = pd.DataFrame({\"Population\": population, \"Area\": area})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if the indices don't match, it doesn't matter.\n",
    "Missing values are included as `NaN` (Not a Number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({\"Zurich\": 87.88, \"St.Gallen\": 39.41,\"Geneva\": 15.92,\"Rapperswil\": 1.74,\"Bern\": 51.62})\n",
    "population = pd.Series({\"Zurich\": 415215, \"St.Gallen\": 75806,\"Rapperswil\": 7601,\"Bern\": 133791, \"Rüti (ZH)\": 12170})\n",
    "\n",
    "df = pd.DataFrame({\"Population\": population, \"Area\": area})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing structural information can be done by `index` and `columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Index:   {df.index}\")\n",
    "print(f\"Columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing `Series` is possible by using the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing & Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have some fun with `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(np.linspace(0,1,5), index=list(\"abcde\"))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access values like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"b\":\"d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When slicing with indices, using explicit indices (e.g. \"b\":\"d\") will include all - inclusive the end (e.g. \"d\").\n",
    "When using implicit indices (e.g. 0:2), the value at 2 is not included.\n",
    "But most of the time, we will work with explicit indices as many times indices are timestamps, names or some other identifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since accessing with implicit indices is possible, we might run into problems with integer indices.\n",
    "To solve these issues, `loc[range]` (using the explicit index) and `iloc[range]` (using the implicit index) are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intData = pd.Series(range(1,6), range(0,10,2))\n",
    "intData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intData.loc[4:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intData.iloc[4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there is more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"a\" in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use *masking* and *fancy indexing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data < .5) | (data > .75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"a\", \"e\", \"c\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we can add new values the same way as it works with dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"f\"] = 1.25\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrames` offer simmilar possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({\"Zurich\": 87.88, \"St.Gallen\": 39.41,\"Geneva\": 15.92,\"Rapperswil\": 1.74,\"Bern\": 51.62})\n",
    "population = pd.Series({\"Zurich\": 415215, \"St.Gallen\": 75806,\"Geneva\": 201741,\"Rapperswil\": 7601,\"Bern\": 133791})\n",
    "\n",
    "cities = pd.DataFrame({\"Population\": population, \"Area\": area})\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select `Series` in two different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Although, the latter seems simpler, there are some limitations to it.\n",
    "Using special characters could lead to problems or even make it impossible to use this approach.\n",
    "Further, if columns use the same name as existing methods or fields, it won't work, either.\n",
    "The same is true, if the columns are not `strings` but some other data  type.\n",
    "Thus, for the remainder of this course, we will stick with the first approach by using the name of the column as index argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a `DataFrame`, we can easily extend it with new values.\n",
    "New values can be introduced by either adding a completely new `Series` as column, or we can calculate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"Density\"] = cities[\"Population\"] / cities[\"Area\"]\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with ranges can either be done directly using `[]`, or again with `loc[]`, `iloc[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"St.Gallen\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.loc[\"St.Gallen\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.loc[:\"Rapperswil\", :\"Area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.iloc[:4, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities[\"Density\"] > 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.loc[cities[\"Density\"] > 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.loc[cities[\"Density\"] < 4000, [\"Population\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even transpose a `DataFrame` with one simple call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more possible ways to select values in `DataFrames`.\n",
    "In the next sections and during the course we will continously introduce new ways of interacting with data within `DataFrames`.\n",
    "Feel free to dive deep into `DataFrames` as they will be the main object we will work with during this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic operations we used to work with NumPy arrays are also available for `DataFrames`.\n",
    "So this is absolutely possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(range(0,11), columns=[\"Value\"])\n",
    "df[\"Add2\"] = df[\"Value\"] + 2\n",
    "df[\"Sub1\"] = df[\"Value\"] - 1\n",
    "df[\"Mul3\"] = df[\"Value\"] * 3\n",
    "df[\"Div2\"] = df[\"Value\"] / 2\n",
    "df[\"FloorDiv2\"] = df[\"Value\"] // 2\n",
    "df[\"Pow2\"] = df[\"Value\"] ** 2\n",
    "df[\"Mod3\"] = df[\"Value\"] % 3\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other functions are also available (please note that the following examples are not exhaustive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Value\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.prod() # that's kinda stupid since in every column but one is a 0 present, d'oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to combine `DataFrames` and `Series`.\n",
    "For starters, there are `pd.concat()` and `DataFrame.append()` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list(\"AB\"))\n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list(\"AB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the indices are taken from both data frames per default.\n",
    "If we want to ignore this behavior, we can use the `ignore_index` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `append()` can be used likewise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `axis` parameter, we can define in what direction the `DataFrames` are put together.\n",
    "Per default `axis` is set to `\"index\"`, thus the parts are stacked on each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both functions work also with `Series`.\n",
    "We don't have to build all `DataFrames` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser1 = pd.Series([5,6], index=[0,1], name=\"C\")\n",
    "pd.concat([df1, ser1], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And even with multiple `Series` at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser2 = pd.Series([7, 8], index=[0, 1], name=\"D\")\n",
    "pd.concat([df1, ser1, ser2], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that these functions won't change instances, but return new instances of `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, ser1], axis=\"columns\")\n",
    "print(df1)\n",
    "print()\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples above simply put `DataFrames` and `Series` together.\n",
    "While working with multiple `DataFrames`, it's more likely that we need to combine them based on specific values in a specific column.\n",
    "Thus, for a more complex combinations of `DataFrames`, there are `pd.merge()` and `DataFrame.join()` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantons = pd.DataFrame({ \"Canton\" : [\"Bern\", \"Zurich\", \"Luzern\", \"Uri\"], \"Abbr\" : [\"BE\", \"ZH\", \"LU\", \"UR\"]})\n",
    "population = pd.DataFrame({\"Population\" : [1031126, 1504346, 406506, 36299], \"Canton\" : [\"Bern\", \"Zurich\", \"Luzern\", \"Uri\"]})\n",
    "\n",
    "print(cantons)\n",
    "print()\n",
    "print(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(cantons, population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, `pd.merge()` combines the two `DataFrames` as expected without duplicating the \"Canton\" column.\n",
    "If there are no common column, `pd.merge()` will fail.\n",
    "In this case, we have to specify how to combine the `DataFrames` by using the `left_on` and `right_on` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.DataFrame({\"Cant\" : [\"Bern\", \"Zurich\", \"Luzern\", \"Uri\"], \"Url\" : [\"https://www.be.ch/\", \"https://www.zh.ch/\", \"https://www.lu.ch/\", \"http://www.uri.ch/\"]})\n",
    "pd.merge(cantons, links, left_on=\"Canton\", right_on=\"Cant\").drop(\"Cant\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case there are multiple columns that could be used to combine, or we simple want to specify the column, we could use the `on` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(cantons, population, on=\"Canton\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we rather want to merge `DataFrames` based on their indices.\n",
    "The `pd.merge()` function also allows this by stating it with the `left_index` and `right_index` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantonsI = cantons.set_index(\"Canton\") # setting Series as index\n",
    "populationI = population.set_index(\"Canton\")\n",
    "linksI = links.set_index(\"Cant\")\n",
    "\n",
    "df1 = pd.merge(cantonsI, populationI, left_index=True, right_index=True)\n",
    "pd.merge(df1, linksI, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could mix the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linksI = links.set_index(\"Cant\")\n",
    "\n",
    "pd.merge(df1, linksI, left_on=\"Canton\", right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since usually there are indices defined, the `DataFrame.join()` performs an index-based merge out-of-the-box.\n",
    "And since the function returns a new `DataFrame`, we can also use a technique called *method chaining* to join multiple `DataFrames` in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantonsI = cantons.set_index(\"Canton\")\n",
    "populationI = population.set_index(\"Canton\")\n",
    "linksI = links.set_index(\"Cant\")\n",
    "\n",
    "cantonsI.join(populationI).join(linksI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation and Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with larger datasets, which is what we will do during this course, enforces functions to aggregate and group data into more manageable junks.\n",
    "We've already seen that `sum()` and `prod()` work with `DataFrames` and `Series`, respectively.\n",
    "And as you might expect, the other functions that we have used on the NumPy arrays also exist.\n",
    "\n",
    "- `mean()`\n",
    "- `median()`\n",
    "- `min()`\n",
    "- `max()`\n",
    "- `std()`\n",
    "- `var()`\n",
    "\n",
    "And there are new ones as well.\n",
    "\n",
    "- `count()` number of items in a `Series` (`NaN` is excluded)\n",
    "- `head(n)` first `n` rows\n",
    "- `first()` first item in `Series` if the index is a date\n",
    "- `tail(n)` last `n` rows\n",
    "- `last()` last item in `Series` if the index is a date\n",
    "- `info()` shows a summary of the `DataFrames` structure\n",
    "- `describe()` shows stats of the `DataFrames` content\n",
    "- `quantile()` returns the requested percentile\n",
    "\n",
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#computations-descriptive-stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation = pd.read_csv(\"Demo_CH_2018.csv\", sep=\";\") # you'll understand this line in a moment\n",
    "chPopulation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the functions are quite simple to apply on a `DataFrame` - like getting the median of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent a warning, we set `numeric_only=True`.\n",
    "Otherwise, the warning would mention that some columns (in our case `Canton` and `Lang`) were ignored, but we did not explicitely excluded them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that these functions will return a value for each column, but they do not have to be in the same row.\n",
    "If we check for `max()` or `min()` we get the following results that won't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation[chPopulation[\"Dec 2018\"] == chPopulation[\"Dec 2018\"].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation[chPopulation[\"Dec 2018\"] == chPopulation[\"Dec 2018\"].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, be careful and crosscheck your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these functions can also be applied on rows instead of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation.mean(axis=1, numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And while we are at it, it is also possible to create more complex filtering.\n",
    "For example, it's quite easy to get the cantons which are in the lowest quartile (quarter with the smallest values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation[chPopulation[\"Dec 2018\"] <= chPopulation.quantile(.25)[\"Dec 2018\"]].sort_values(\"Dec 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check indices for\n",
    "- intersections (`.intersection()`)\n",
    "- unions (`.union()`)\n",
    "- symmetric differences (`.symmetric_difference()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = pd.Index([1,2,3,4,5])\n",
    "idx2 = pd.Index([1,3,5,7])\n",
    "\n",
    "print(f\"Intersection: {idx1.intersection(idx2)}\")\n",
    "print(f\"Union:        {idx1.union(idx2)}\")\n",
    "print(f\"Difference:   {idx1.symmetric_difference(idx2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hierarchical Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a side note for now, it is possible to work with multi-dimensional indices.\n",
    "If we acutally have to work with them, we will cover the topic.\n",
    "But for now, we just show you an example how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = pd.Index([\"Zurich\", \"Bern\"])\n",
    "d2018 = pd.Series([1504346, 1031126], index=ix)\n",
    "d2017 = pd.Series([1487969, 1026513], index=ix)\n",
    "d2016 = pd.Series([1466424, 1017483], index=ix)\n",
    "history = pd.DataFrame({2018: d2018, 2017: d2017, 2016: d2016})\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mHistory = history.stack()\n",
    "mHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mHistory.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = mHistory.unstack()\n",
    "flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen some magic with Pandas, let's go a step further.\n",
    "The examples above primarily showed simple `DataFrames` that we used to demonstrate certain features of Pandas.\n",
    "But as you may noticed, in the last example, we got a bit lazy and loaded our demo data from a file.\n",
    "All the cool stuff Pandas allows us to do is only cool, when we can use it on real data.\n",
    "Thus, we need ways to access external sources.\n",
    "\n",
    "Pandas offers many different functions to load data into a `DataFrames` without filling it by hand.\n",
    "In the following sections, we demonstrate the most relevant of them.\n",
    "For a complete list of `read_*()` functions, please check the reference provided above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv(\"./Demo.csv\", sep=\";\")\n",
    "csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.read_excel(\"./Demo.xlsx\")\n",
    "excel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = pd.read_json(\"./Demo.json\", orient=\"index\")\n",
    "json.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refernece: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_html.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = pd.read_html(\"./Demo.html\", index_col=0)\n",
    "html[0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html#serialization-io-conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to save `DataFrames` as files.\n",
    "We won't cover this topic for now, but you are free to explore this feature by yourself.\n",
    "If it gets relevant in this course, we will cover the topic to some level.\n",
    "But it's pretty simple.\n",
    "Just call the corresponding `to_*()` function and give it a filename."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01 - NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array with 10 elements and all are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array with 4 elements having a value of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2-dimensional (3 by 4) array with the values of 1 to 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 17 evenly spaced values from 2 to 438."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the squares for the values from 1 to 25 by using UFuncs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random number generator with seed 453.\n",
    "Then generate 12 values and show only the values that are below .3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random number generator with seed 2351, generate 10000000 values and calculate the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a random number generator with seed 57963, generate 100'000'000 values, and check if at least one value is above .999 and if so, how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex02_01_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02 - Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file **Ex02_02_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the structure of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the stats of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you see, is the data of the world happyness report of 2019.\n",
    "All the values, besides the actuall score just denote how much they contribute to the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now show the first 10 and last 3 entires of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the entry of Switzerland and store it in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How far behind are we compared to the happiest nation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How far above are we compared to the least happiest nation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In which country contributes the GDP per capita the most to the happines score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the score as integer to each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex02_02_Sol.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
