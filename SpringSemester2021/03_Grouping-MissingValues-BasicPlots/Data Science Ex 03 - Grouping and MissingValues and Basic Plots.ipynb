{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ex 03 - Grouping, Missing Values & Basic Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "03.03.2021, Lukas Kretschmar (lukas.kretschmar@ost.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have some Fun with Data and Visualization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to see how you can remove rows that have missing values or how you can replace them.\n",
    "And you are going to learn how you can visualize data with plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chPopulation = pd.read_csv(\"Demo_CH_2018.csv\", sep=\";\")\n",
    "chPopulation.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having seen some basic aggration functions, we now go a step further and play around with some more complex applications.\n",
    "Aggregations on the whole `DataFrame` usually take away to much detail.\n",
    "Thus, we need a way to aggregate only parts of the `DataFrame`.\n",
    "\n",
    "Basically, we want to execute the following steps:\n",
    "- split (taking junks apart)\n",
    "- apply (using functions on junks)\n",
    "- combine (putting the results together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting `DataFrames` is done by using the `groupby()` function.\n",
    "The result is just another object but we cannot see actual data.\n",
    "We first have to apply another function on the group.\n",
    "\n",
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = chPopulation.groupby(\"Lang\")\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a group, we can now apply functions on it (as seen above).\n",
    "Usually, the *apply* and *combine* steps are executed in one go.\n",
    "For example, you can decompose the `count()` function to *apply* (return a value of 1 for every entry) and *combine* (add the results of every entry together)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to apply some specific functions on our groups, we have the following possibilities:\n",
    "- `aggregate()` takes some existing aggregation functions and applies them on a group\n",
    "- `filter()` filters results that don't match a predicate\n",
    "- `transform()` transforms given values of a `Series` to other values but does not have to reduce them (as `aggregate()` must)\n",
    "- `apply()` applies a given function onto a `DataFrame` but still using the groups\n",
    "\n",
    "These functions are also part of every `DataFrame` object.\n",
    "So you do not need to create groups first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say, we want some basic stats on our groups.\n",
    "We could do this by using `aggregate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages[[\"Jan 2018\", \"Dec 2018\"]].aggregate([np.min, np.median, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or what if we want only the entries of groups, where the median of a group is above a certain value.\n",
    "Then we could use the `filter()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages.filter(lambda g : g[\"Dec 2018\"].median() > 200000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `transform()`, we can calculate how many more people are living in a canton than the median of the group the canton is part of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedMedian = languages.transform(lambda col : col - col.median())\n",
    "groupedMedian.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedMedian = pd.merge(groupedMedian, chPopulation[[\"Canton\", \"Lang\"]], left_index=True, right_index=True)\n",
    "groupedMedian.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if the functions presented above do not have enough flexibility, we could rely on `apply()`.\n",
    "Since `apply()` works on a whole `DataFrame`, it is even possible to extend the instance or change existing columns.\n",
    "\n",
    "For example, we can calculate the difference in population compared to the smallest canton of each group and add this information to the `DataFrame` in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcYearlyDiff(df):\n",
    "    df[\"Diff\"] = df[\"Dec 2018\"] - df[\"Dec 2018\"].min()\n",
    "    return df\n",
    "\n",
    "languages.apply(calcYearlyDiff).sort_values([\"Lang\", \"Diff\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are aware that using these functions isn't the simplest task, but it's just a matter of knowing their abbilities and experience.\n",
    "So don't worry if you are now a bit puzzled, during the remainder of this course you will get pretty familiar with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Quality of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen some simple dummy `DataFrames` and loaded a bit more complex structures.\n",
    "But they never had any values missing.\n",
    "When working with real data, for example log files of a machine, you will encounter many missing values or values that just don't make sense (e.g. sensor gone rouge).\n",
    "In this section, we'll show you how you can spot such values and how you can get rid of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, missing values are indicated in three different ways:\n",
    "- Entry is empty\n",
    "- NaN/NA indicates a missing value\n",
    "- A specific value indicates a missing value (e.g. -1 when the valid values have to be > 0)\n",
    "\n",
    "If Pandas encounters such values, it will handle them as follows:\n",
    "- Empty gets `None` or `np.nan` (Pandas default behavior favors `np.nan`)\n",
    "- NaN/NA gets `np.nan` or the column is handled as text\n",
    "- Specific values cannot be detected as they are valid values. Here, knowledge of the data scientist is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.read_csv(\"./Demo_Missing.csv\", sep=\";\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a look at the structure, you see that Pandas can handle missing values pretty smoothly.\n",
    "Although, all but the first column contain integers, Pandas reads them as floating points because `NaN` is a specific floating point value.\n",
    "Only the last column is interpreted as integer.\n",
    "But reading files with missing values is a piece of cake for Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data as `DataFrame`, we can check the columns with the following functions:\n",
    "- `isna()` or `isnull()`\n",
    "- `notna()` or `notnull()` (opposite of `isna()`/`isnull()`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply `isna()` on a `DataFrame`, we get a `DataFrame` containing booleans.\n",
    "For a first check, we can use `sum()` on this result to get a first impression of how bad it is.\n",
    "Since `True` counts as 1, we get the number of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied twice, we get an overall number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can get the percentage of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why we want to detect missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with missing values is pretty simple.\n",
    "They mess around with our functions.\n",
    "For example, if they have some specific value that indicated the absence of a value, an aggregation will return a wrong result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing[\"Specific\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing[\"Specific\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = missing[\"Specific\"]\n",
    "specific[specific >= 0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, `NaN` values are handled correctly with the built-in functions.\n",
    "But if we define our own functions, we could run into trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"min: {missing['NaN'].min()}\")\n",
    "print(f\"max: {missing['NaN'].max()}\")\n",
    "print(f\"sum: {missing['NaN'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySum(series):\n",
    "    sum = 0\n",
    "    for v in series:\n",
    "        print(v)\n",
    "        sum += v # sum = sum + v\n",
    "    return sum\n",
    "\n",
    "missing[\"NaN\"].aggregate(mySum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = missing[\"NaN\"]\n",
    "nan[nan.notna()].aggregate(mySum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most simple approach of dealing with missing values is to remove the entire row that is not complete.\n",
    "Pandas offers the `dropna()` method that does exactly this.\n",
    "\n",
    "Please note: Calling this function returns a new object with the rows dropped but does not change the original object.\n",
    "Thus, when getting rid of rows, make sure that you assign the newly created `DataFrame` to a variable so you can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've seen with aggregation functions, we can also drop all columns that contain `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these methods are a bit too radical, it is also possible to remove some rows or columns with `drop()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.drop(0) # removing row with index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.drop([1,3]) # removing rows with index 1 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.drop(\"NaN\", axis=1) # removing column \"NaN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a bool-array to select the rows we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing[missing[\"NaN\"].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, removing data can falsify the outcome of your analysis, since the \"healthy\" entries in a row or column can contain valuable information.\n",
    "On the other hand, if a certain amount of rows or columns must be fixed to work with, it can be simpler just to ignore them completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides removing, we can also fill holes in our dataset.\n",
    "Several strategies exist to accomplish that.\n",
    "\n",
    "- Setting a fixed value\n",
    "- Taking the value above\n",
    "- Taking the value below \n",
    "\n",
    "The method that offers these strategies in Pandas is called `fillna()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, everywhere a value was missing, it got replaced by `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't want every value to be the same, we can provide a dictionary specifying which values to take per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna({\"Text\": \"Zero\", \"NaN Text\": 32})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could take values based on the existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna({\"Empty\" : missing[\"Empty\"].mean(), \"NaN\" : missing[\"NaN\"].min()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other two strategies, taking values from above or below can be acomplished by stating the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna(method=\"ffill\") # forward fill will take the value from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna(method=\"bfill\") # backward fill will take value from below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods also work using the values of the same row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing.fillna(method=\"ffill\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are left, is the case of `-1` in the last column.\n",
    "To resolve this, there is no simple method since Pandas cannot assume by default that `-1` representats the absence of a value.\n",
    "Thus, we have to replace the value by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = missing.copy()\n",
    "copy[\"Specific\"] = copy[\"Specific\"].replace(-1, 43)\n",
    "copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we either used a value or dictionary to replace missing values.\n",
    "But some other applications can be powerful for more specifc cases.\n",
    "- `transform()` with a custom method\n",
    "- `fillna(Series)`\n",
    "- `fillna()` in combination with `groupby()` and `apply()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we could imagine what the missing values must be, we can fix the `DataFrame` by calculating the values.\n",
    "Using the `transform()` method, we can replace `Series` by `Series` and calculating values where they are not defined.\n",
    "\n",
    "Please note: This is a solution for the given `DataFrame`, you cannot assume that this method handles future problems.\n",
    "But it shows a possible pattern to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNa(col):\n",
    "    if col.dtype not in {np.dtype(\"int64\"), np.dtype(\"float64\")}: # checking if we have a number\n",
    "        return col                                                # if the Series is not a number (e.g. object) we return the Series immediately\n",
    "    values = []\n",
    "    for i, v in col.items():                                      # going through every item in the Series\n",
    "        value = getValueFor(v, i, col)                            # calculating the value\n",
    "        values.append(value)                                      # adding the value to the list\n",
    "    return pd.Series(values, name=col.name, index=col.index)      # build new series and returning it\n",
    "\n",
    "def getValueFor(v, i, col):\n",
    "    if ~np.isnan(v) and v >= 0:                                   # checking if not NaN (as in most cases) and greater or equal than 0 (handling our special case), \n",
    "        return v                                                  # and just returning the value\n",
    "    # if NaN, calculate the mean\n",
    "    print(f\"NaN @ {col.name}[{i}] -> Taking values from {max(i - 1, 0)} & {min(i + 1, len(col)-1)}\")\n",
    "    above = col.iloc[max(i - 1, 0)]                               # getting the value above the current index i\n",
    "    below = col.iloc[min(i + 1, len(col)-1)]                      # getting the value below the current index i\n",
    "    value = np.mean([above, below])                               # calculating the mean of both values\n",
    "    print(f\"Mean: {value}\")\n",
    "    return value\n",
    "\n",
    "missing.transform(fillNa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach, inserting a `Series` into `fillna()`, works pretty straight forward.\n",
    "If a value is missing, the corresponding value of the `Series` with the same index is taken.\n",
    "\n",
    "Please note: Here, index means the `Series` index and not the location (0 to max).\n",
    "Thus, the order of the provided `Series` doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingValues = pd.Series([np.nan, 10, 20, np.nan, 40, np.nan])\n",
    "print(missingValues)\n",
    "print()\n",
    "\n",
    "fillin = pd.Series(list(range(6)))\n",
    "print(fillin)\n",
    "print()\n",
    "\n",
    "missingValues.fillna(fillin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infill = fillin[::-1] # reverse order\n",
    "missingValues.fillna(infill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the values were replaced the same way, despite the `infill` `Series` is ordered differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `fillna()` in combination with `groupby()` and `apply()` is a slightly more complicated approach, but more powerful.\n",
    "This approach comes in handy when we want to fill in an aggregated value, but the aggregation only considers parts of the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a list of students, with their current semester and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.read_csv(\"./Demo_Students.csv\")\n",
    "students.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, some age information is missing.\n",
    "\n",
    "We can now group the students by their semester and get the mean age per semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semesters = students.groupby(\"Semester\")[\"Age\"]\n",
    "semesters.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can apply some function per students per semester.\n",
    "The call to `fillna()` now takes the mean value per group (the same as setting one fixed value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students[\"Age\"] = semesters.apply(lambda g : g.fillna(np.round(g.mean())))\n",
    "students.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we've only worked with showing numbers or tables.\n",
    "But data science, especially when communicating results, is a visual task.\n",
    "Well, visualization also helps understanding given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Python, Jupyter Notebooks and Pandas, we'll use the Matplotlib module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since we want to use plots within this notebook (and every notebook during this course), we also need to apply the following magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command enables a feature within the notebook that it will show plots as soon as a `plot()` method is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this module is modeled after a visualization library from MATLAB, the plots can look sometimes a bit - let's say Spartanic.\n",
    "Thus, we recommend to use Seaborn to enhance coloring.\n",
    "But it's not mandatory to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Plots do not mind correlation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will see, plots will take two arrays.\n",
    "They are not interested in values and a function - the arrays just have to be of the same length and the plot method will stitch together the values based on their position within the array.\n",
    "Thus the following code is totally valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "plt.plot(np.arange(0,20,1), rng.randint(-10, 10, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see during this course that this freedom is pretty cool when working with plots.\n",
    "Thus, we don't mind, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drawing Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.plot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pyplot` module comes with two interfaces.\n",
    "A MATLAB-style interface and an object-oriented-style interface.\n",
    "You can spot the difference pretty simple, since the former only contains methodcalls to `plt` and the latter uses results from method calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATLAB-style\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(2, 1, 1) # Select left panel (2 rows, 1 column, 1st panel)\n",
    "plt.plot(x, np.sin(x))\n",
    "\n",
    "plt.subplot(2, 1, 2) # Select right panel (2 rows, 1 column, 2nd panel)\n",
    "plt.plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OO-style\n",
    "fig, ax = plt.subplots(2) # Getting figure and array of axis (aka panels)\n",
    "ax[0].plot(x, np.sin(x))\n",
    "ax[1].plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We recommend using the OO-style plot, since the interface is much more cleaner and we don't have to rely on side-effects.\n",
    "Within this course, all examples will be using this style.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to plot multiple lines, we simply can call the plot method multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x))\n",
    "ax.plot(x, np.cos(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can use plots in two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2, figsize=(14, 7))\n",
    "ax[0,0].plot(x, np.sin(x))\n",
    "ax[0,1].plot(x, x)\n",
    "ax[1,0].plot(x, np.cos(x))\n",
    "ax[1,1].plot(x, -x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With xlim and ylim, we can set the ranges of each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set(xlim=(2, 6))\n",
    "ax.plot(x, np.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set(ylim=(-10, 20))\n",
    "ax.plot(x, x + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Styling Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can color lines by using the `color` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), color=\"green\")\n",
    "ax.plot(x, np.sin(x + 1), color=\"r\")\n",
    "ax.plot(x, np.sin(x + 2), color=\"#123456\") # Hex color\n",
    "ax.plot(x, np.sin(x + 3), color=\".5\") # Grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change how a line is drawn by using the `linestyle` parameter.\n",
    "Here, you can use specific keywords or characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, x, linestyle=\"solid\")\n",
    "ax.plot(x, x + 1, linestyle=\"dashed\")\n",
    "ax.plot(x, x + 2, linestyle=\"dashdot\")\n",
    "ax.plot(x, x + 3, linestyle=\"dotted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, x, linestyle=\"-\") # solid\n",
    "ax.plot(x, x + 1, linestyle=\"--\") # dashed\n",
    "ax.plot(x, x + 2, linestyle=\"-.\") # dashdot\n",
    "ax.plot(x, x + 3, linestyle=\":\") # dotted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the lazy ones of you who want to combine color and linestyle, it goes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, x, \"-r\")\n",
    "ax.plot(x, x + 1, \"--g\")\n",
    "ax.plot(x, x + 2, \"-.k\")\n",
    "ax.plot(x, x + 3, \":c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent confusion, it's a good idea to set labels on plots and figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, constrained_layout=True) # with constrained_layout we prevent overlap of labels\n",
    "fig.suptitle(\"This figure shows sin(x) and cos(x)\")\n",
    "ax[0].plot(x, np.sin(x))\n",
    "ax[0].set(title=\"y = sin(x)\", xlabel=\"x\", ylabel=\"sin(x)\")\n",
    "\n",
    "ax[1].plot(x, np.cos(x))\n",
    "ax[1].set(title=\"y = cos(x)\", xlabel=\"x\", ylabel=\"cos(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And since both plots use the same values for the horizontal axis, we can also share them with `sharex` (there is also a `sharey`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, sharex=True)\n",
    "fig.suptitle(\"This figure shows sin(x) and cos(x)\")\n",
    "ax[0].plot(x, np.sin(x))\n",
    "ax[0].set(title=\"y = sin(x)\", ylabel=\"sin(x)\")\n",
    "\n",
    "ax[1].plot(x, np.cos(x))\n",
    "ax[1].set(title=\"y = cos(x)\", xlabel=\"x\", ylabel=\"cos(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only having one line, it is often enough setting a title to the plot.\n",
    "But as soon as we have multiple lines shown in one figure, a legend might get handy.\n",
    "To get this, we simply define a label per plot and enable the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), label=\"sin(x)\")\n",
    "ax.plot(x, np.cos(x), label=\"cos(x)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the legend is in a pretty good spot.\n",
    "This is due to its default value for finding a location is set to `best`.\n",
    "But we can specify where we want the legend.\n",
    "We can define a combination of the following value pairs `upper` or `lower` and `right` or `left`.\n",
    "Further, `center` is applicable for either of these values or `best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), label=\"sin(x)\")\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can even create multiple legends.\n",
    "This is a bit trickier, but also no rocket science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sinLine = ax.plot(x, np.sin(x), label=\"sin(x)\")\n",
    "cosLine = ax.plot(x, np.cos(x), label=\"cos(x)\")\n",
    "\n",
    "sinLeg = plt.legend(handles=sinLine, loc=\"lower right\")\n",
    "ax.add_artist(sinLeg)\n",
    "cosLeg = plt.legend(handles=cosLine, loc=\"upper left\")\n",
    "ax.add_artist(cosLeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can change the appearance of the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2)\n",
    "ax[0].plot(x, np.sin(x), label=\"sin(x)\")\n",
    "ax[0].legend(loc=\"center\", frameon=False)\n",
    "\n",
    "ax[1].plot(x, np.cos(x), label=\"cos(x)\")\n",
    "ax[1].legend(loc=\"center\", shadow=True, framealpha=.5, borderpad=1.5, fancybox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, not everythin is a line.\n",
    "Chances are that we frequently have to deal just with points.\n",
    "\n",
    "Continuing with the already know, scatter plots can be drawn quite easily.\n",
    "We just use a specific style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 30) # we reduce the number of points to increase the distance between our points\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can even combine the two styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), \"-or\") # - for the line, o for the points, and r for the color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can draw the two styles on top of each other, but keep in mind that the order of `plot()`-calls matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), \"ob\")\n",
    "ax.plot(x, np.sin(x), \"-r\", linewidth=3)\n",
    "ax.set(title=\"Line on top of Points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, np.sin(x), \"-r\", linewidth=3)\n",
    "ax.plot(x, np.sin(x), \"ob\")\n",
    "ax.set(title=\"Points on top of the Line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using points, there are many possible ways of drawing them.\n",
    "The type of point is called `marker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "for marker in list(\"o.,x+v^<>sd\"):\n",
    "    ax.plot(rng.rand(5), rng.rand(5), marker, markersize=rng.randint(8,16), label=f\" = {marker}\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the `plot()` method is pretty simple.\n",
    "But sometimes, a generic method isn't the right choice.\n",
    "Maybe we need some more flexibility in drawing our points.\n",
    "\n",
    "If this is the case, Matplotlib has you covered - with the `scatter()` method.\n",
    "The simplest usage looks like a call of the `plot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, np.sin(x)) # we can omit the marker since scatter() will draw points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scatter()` shows it's power when we want to encode more information in the points.\n",
    "So we can change the transparency `alpha`, color `c` and size `s` of every point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "px = rng.randn(50)\n",
    "py = rng.randn(50)\n",
    "colors = px * py # The color depends on the location\n",
    "sizes = abs(px * py) * 1000 # The size depends on the location\n",
    "\n",
    "fix, ax = plt.subplots(1,2, figsize=(20,5))\n",
    "ax[0].scatter(px, py, c=colors, s=sizes, alpha=.5)\n",
    "fig.colorbar(mappable=ax[0].collections[0], ax=ax[0]) # with ax.collections[0] we get metadata of the scatterplot (here, we need the cmap to know the used colors)\n",
    "\n",
    "# Use other colors\n",
    "ax[1].scatter(px, py, marker=\"v\", c=colors, s=sizes, alpha=.8, cmap=\"viridis\")\n",
    "fig.colorbar(mappable=ax[1].collections[0], ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find more colormaps under https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html - but depending on using seaborn or not, they might look a bit smoother than shown on the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A note on performance:** Since `scatter()` renders each point individually, it could result in bad performance when drawing large datasets.\n",
    "In this case and if you can do without different point sizes and/or colors, use `plot()` where each point is a copy of one point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01 - Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following exercise, we'll work with data from the file **Ex03_01_Data.csv**.\n",
    "So, at first, load the file into a `DataFrame` and show the first 5 lines to check if the file was loaded successfully.\n",
    "This file contains video games sales and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, some values are missing.\n",
    "Show the percentage of missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be radical, drop all rows with missing values.\n",
    "How many entries are left?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all columns that have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all games that do not have a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that many games were not scored by critics, thus drop all the games that have no value in the column *Critic_Score*.\n",
    "And check if all entries of the result have a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the *Developer* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all games with a *User_Score* lower than 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that zero sales means missing data.\n",
    "Drop all games were the european marked data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, since many values are missing, drop all colums where more than 40% of values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex03_01_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02 - Replacing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset **Ex03_02_Data.csv** and create a copy of it, since you will modify the `DataFrame`.\n",
    "The goal of this exercise is to get a complete data set (no values are missing) at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which columns do miss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, scores for many games are missing.\n",
    "But let's start with something easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have publishers for all games, let's set them also as developers where they are not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the critic count, we just take the mean of all critic counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fill the user score.\n",
    "Let's assume it's a 100th of the global sales added to the median user score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenges!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the year of release, we will take the platform into account.\n",
    "Set the years to the median year per platform where the release year is not given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the critic score.\n",
    "We assume that the score is the median per platform, genre and publisher.\n",
    "Since for some games, no score can be calculated, we then take only genre and publisher and for the remaining without a score, we just take the genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are no more missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex03_02_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex03 - Line Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a horizontal line from `x=[0, 10]` at `y=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a vertical line at `x=5` from `y=[-1, 7.5]`.\n",
    "And the line should be dotted and red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the `cos()` from $\\pi$ to 5$\\pi$.\n",
    "The curve should be green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a line that connects 50 random numbers in the range of `x=[-250, 250]` and `y=[-250, 250]`.\n",
    "`x` and `y` are independent of each other.\n",
    "The line should be styled as dash-dot and black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot `y=x^3` with `x=[0, 20]` but limit the view to `y=[100, 7000]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex03_03_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex04 - Scatter Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot 50 random points between `x=[-50, 50]` and `y=[-50, 50]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now draw the points as triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the size of each triangle is bound to its location with smallest points at `[-50, -50]` having `size=10` and largest at `[50, 50]` having `size=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the color of each triangle is bound to its `x` value.\n",
    "You can choose the colormap individually.\n",
    "Sizes are fix at `150`.\n",
    "And don't forget to plot the colorbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the symbols are bound to the points location.\n",
    "- `x & y < 0` use a blue square with `alpha=.25`\n",
    "- `x & y >= 0` use a red rhombus with `alpha=.75`\n",
    "- `x < 0 & y >= 0` use a green point with `alpha=.5`\n",
    "- `x >= 0 & y < 0` use a black x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex03_04_Sol.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
