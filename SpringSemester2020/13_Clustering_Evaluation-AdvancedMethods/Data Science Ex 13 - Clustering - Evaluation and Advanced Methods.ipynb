{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ex 13 - Clustering (Evaluation & Advanced Methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.05.2020, Lukas Kretschmar (lukas.kretschmar@hsr.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have some Fun with Evaluation of Clusters and Advanced approaches!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we are going to have a look at how you can evaluate clusters.\n",
    "And further, we introduce another clustering approach out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we head into the details of this introduction, we need some example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(\"./Demo_Clustering.csv\")\n",
    "data = data_full[[\"x\", \"y\"]]\n",
    "data_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "data_full.plot.scatter(\"x\", \"y\", ax=ax, c=\"label\", cmap=\"rainbow\", colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, finding the correct number of clusters or just reasoning if and why clusters make sense, is a science for itself.\n",
    "There are methods out there we can use to come a bit closer to a good answer, as you saw with the *elbow method*.\n",
    "Here, we introduce another approach - called the **silhouette analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html & https://en.wikipedia.org/wiki/Silhouette_(clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The silhouette analysis shows how distinct clusters are.\n",
    "The analysis uses a concept called *silhouette value* which ranges between `-1` and `1` and shows how close a point is to the other points of its cluster.\n",
    "A value close to `1` means that a point is close to the points in its cluster, but far away to the points of the next closest cluster.\n",
    "The closer the value is to `0`, the closer a value is also to another cluster.\n",
    "And negative values indicate that points of another cluster are actually closer than the points of its current cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically speaking, we have values\n",
    "- $a(i)$: mean distance of point $i$ to the points in the same cluster\n",
    "- $b(i)$: mean distance of point $i$ to the points of the next closest cluster\n",
    "\n",
    "and the formulas for calculating the silhouette value\n",
    "\n",
    "- $s(i) = \\frac{b(i) - a(i)}{max\\{a(i),b(i)\\}}$: if $i$ is not alone in a cluster\n",
    "- $s(i) = 0$: if $i$ is the only point in its cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have look what this would mean for our example data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the silhouette analysis relies on distances between points, clustering algorithms like k-Means are better suited than others (i.e. density-based approaches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simpify the visualization, we create a helper method that handles all the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from matplotlib import cm\n",
    "\n",
    "def silhouetteAnalysis(data, model, n_clusters):\n",
    "    m = clone(model)                                 # Create copy of the model\n",
    "    m.set_params(n_clusters=n_clusters)              # Setting the numbers of clusters\n",
    "    l_pred = m.fit_predict(data)\n",
    "    coef = silhouette_score(data, l_pred)            # Get the silhouette coefficient\n",
    "    print(f\"Silhouette coefficient for {n_clusters}: {np.round(coef, 6)}\")\n",
    "    values = silhouette_samples(data, l_pred)        # Get the silhouette values\n",
    "    colors = cm.get_cmap(\"rainbow\", n_clusters)      # Getting colors\n",
    "    fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "    fig.suptitle(f\"Silhouette Analysis with {n_clusters} Clusters\")\n",
    "    margin = 10\n",
    "    y_bottom = margin\n",
    "    # Plotting the silhouette values\n",
    "    for c in range(n_clusters):\n",
    "        values_c = values[l_pred == c]               # Just getting values of cluster c\n",
    "        values_c = np.sort(values_c)                 # Sorting the values\n",
    "        size_c = len(values_c)                       # Getting the number of values\n",
    "        y_top = y_bottom + size_c                    # Calculating the value on the y-axis to draw to\n",
    "        color = colors(c/n_clusters)                 # Selecting the color of the cluster\n",
    "        # Plotting the values\n",
    "        (ax[0].fill_betweenx(                        # Fill an area\n",
    "            np.arange(y_bottom, y_top),              # Range on y-axis to fill\n",
    "            0,                                       # Start value on x-axis\n",
    "            values_c,                                # End value on x-axis\n",
    "            fc=color, ec=color, alpha=.7))           # Some styling\n",
    "        # Plotting the cluster number to the left\n",
    "        ax[0].text(-.05, y_bottom + .5 * size_c, str(c))\n",
    "        y_bottom = y_top + margin                    # Calculating the next start value on the y-axis\n",
    "    ax[0].axvline(coef, c=\"k\", ls=\"--\")              # Plotting a vertical line for the silhouette coefficient\n",
    "    ax[0].set(title=\"Silhouette Values\", xlabel=\"Silhouette Values\", ylabel=\"Clusters\", yticks=[], xlim=(-.1,1))\n",
    "    \n",
    "    # Plotting the data\n",
    "    centers = m.cluster_centers_\n",
    "    ax[1].scatter(data[\"x\"], data[\"y\"], s=20, c=l_pred, cmap=colors)          # Draw points\n",
    "    ax[1].scatter(centers[:,0], centers[:,1], s=200, c=\"k\")                   # Draw centers in black\n",
    "    for i, c in enumerate(centers):\n",
    "        ax[1].text(c[0], c[1], f\"{i}\", c=\"white\", ha=\"center\", va=\"center\")   # Write cluster number in white\n",
    "    ax[1].set(title=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can simply use the method with our given clustering algorithm and the number of clusters we want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(random_state=42)\n",
    "clusters = [2,3,4,5,6,7,8,9]\n",
    "for c in clusters:\n",
    "    silhouetteAnalysis(data, model, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we get some information back from the silhouette analysis.\n",
    "The scatter plot on the right is mainly for visualization so we see how the clusters were formed.\n",
    "The more interesting plot is on the left.\n",
    "\n",
    "Those \"blades\" represent the silhouette values per cluster.\n",
    "They have these shapes since we sorted the values per cluster in the helper method above.\n",
    "The longer the shape, the more condense the cluster.\n",
    "And the wider a shape, the more points are in the cluster.\n",
    "The vertical dashed line represents the silhouette coefficient which is the mean of all silhouette values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is now to find the best number of clusters.\n",
    "And the silhouette coefficient is an indicator to get there.\n",
    "We have to choose the number by the following criteria:\n",
    "- Silhouette coefficient (higher is better)\n",
    "- Fluctuation of silhouette values (lower is better)\n",
    "- Silhouette values should be close to the silhouette coefficient (closer is better)\n",
    "- Size of clusters (equally distributed can be better)\n",
    "\n",
    "**Note:** Having wastly different sizes of clusters can also be explained by their density.\n",
    "So don't assume that clusters have to be of the same size.\n",
    "Depending on the data (as in the data used here), clusters can be big because they just have many points close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these criteria, we can now assess the given configurations.\n",
    "- **2 clusters**\n",
    " - Silhouette coefficient to low\n",
    " - Clusters to big\n",
    "- **3 clusters**\n",
    " - Fluctuation to big\n",
    " - Cluster 1 is good, clusters 0 & 2 clearly not\n",
    "- **4 clusters**\n",
    " - Fluctuation to big\n",
    " - Clusters 1 & 3 are quite good, 0 & 2 not\n",
    "- **5 clusters**\n",
    " - Looks promising\n",
    " - But cluster 2 indicates that it's quite scattered\n",
    "- **6 clusters**\n",
    " - Better than with 5\n",
    " - But cluster 5 indicates that it's still scattered\n",
    "- **7 clusters**\n",
    " - Has a lower silhouette coefficient as with 6\n",
    " - But the clusters are denser\n",
    "- **8 clusters**\n",
    " - Clusters 0 & 7 indicate that we have to many clusters (more values are closer to 0)\n",
    "- **9 clusters**\n",
    " - Silhouette coefficient is low again\n",
    " - Several clusters have low and even negative values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on this analysis, we suggest that **7 clusters** can be found in this dataset.\n",
    "But **6 clusters** would also be an appropriate conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seaborn packages offers some good visualizations for your data.\n",
    "You'll find a [gallery of its capabilities on its site](https://seaborn.pydata.org/examples/index.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kernel Density Estimation (KDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://seaborn.pydata.org/tutorial/distributions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "sns.kdeplot(data[\"x\"], data[\"y\"], ax=ax[0])\n",
    "\n",
    "ax[1].scatter(data_full[\"x\"], data_full[\"y\"], s=5, c=data_full[\"label\"], cmap=\"rainbow\", alpha=.8)\n",
    "sns.kdeplot(data[\"x\"], data[\"y\"], ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have just 2 dimensinal data, the KDE-jointplot could also be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\"x\", \"y\", data=data, height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=data, x=\"x\", y=\"y\", kind=\"kde\", height=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The darker an area, the higher the density.\n",
    "And you see on the sides a distribution of all the values on one axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a simple hex-bin visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=data, x=\"x\", y=\"y\", kind=\"hex\", height=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pairwise Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use seaborn to simply plot all combinations of features.\n",
    "This can give us a good idea how the data is distributed or we can spot correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Demo_4Features.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data, hue=\"label\", height=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen many different clustering approaches:\n",
    "- Partitioning (k-Means & k-Medoids)\n",
    "- Hierarchical (Agglomerative)\n",
    "- Density-based (DENCLUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another example of a clustering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv(\"./Demo_Clustering.csv\")\n",
    "data = data_full[[\"x\", \"y\"]]\n",
    "data_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "import math\n",
    "\n",
    "def multi_plot(model, data, param, values, cols=2, alpha=.5):  \n",
    "    rows = math.ceil(len(values)/cols)\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(cols*10,rows*10))\n",
    "    for i in range(0, len(values)):\n",
    "        print(f\"Calculating {i+1}/{len(values)} ...\")\n",
    "        m = clone(model)\n",
    "        m.set_params(**{param:values[i]})\n",
    "        l_pred = m.fit_predict(data)\n",
    "        c = int(i % cols)\n",
    "        r = int(i / cols)\n",
    "        data_cluster = data[l_pred != -1]\n",
    "        label_cluster = l_pred[l_pred != -1]\n",
    "        data_outlier = data[l_pred == -1]\n",
    "        ax_rc = ax[r,c] if rows > 1 else ax[c]\n",
    "        data_outlier.plot.scatter(\"x\", \"y\", ax=ax_rc, c=\"k\", alpha=alpha)\n",
    "        data_cluster.plot.scatter(\"x\", \"y\", ax=ax_rc, c=label_cluster, cmap=\"rainbow\", colorbar=False)\n",
    "        ax_rc.set(title=f\"{m}\")\n",
    "    if len(values)%2:\n",
    "        if(rows > 1):\n",
    "            ax[rows-1, cols-1].set_axis_off()\n",
    "        else:\n",
    "            ax[cols-1].set_axis_off()\n",
    "    print(\"Rendering...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN (**D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise) is a well known density-based clustering algorithm.\n",
    "It tries to find cores (with high density) and expands cluster from them.\n",
    "It works well, if clusters have a similar density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DBSCAN()\n",
    "l_pred = model.fit_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "data_cluster = data[l_pred != -1]         # Selecting only points that belong to a cluster\n",
    "label_cluster = l_pred[l_pred != -1]      # Selecting only the labels (clusters) that are actual clusters\n",
    "data_outlier = data[l_pred == -1]         # Selecting the outliers (not part of any cluster)\n",
    "data_outlier.plot.scatter(\"x\", \"y\", ax=ax, c=\"k\", alpha=.5)\n",
    "data_cluster.plot.scatter(\"x\", \"y\", ax=ax, c=label_cluster, cmap=\"rainbow\", colorbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `eps` hyperparameter we can define the distance between to points in a points neighborhood.\n",
    "So, lower values mean smaller neighborhoods.\n",
    "The default is `.5`, thus we start with a smaller value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot(DBSCAN(), data, \"eps\", [.4,.3,.2,.175,.15,.125,.1,.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, since the circles and curves have a higher density, they are not detected when the neighborhood is to big.\n",
    "Only in the last three plots, we see that they get detected.\n",
    "And then, the other cluster are just counted as noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01 - Silhouette Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to run a silhouette analysis for a given sample dataset.\n",
    "We also provide you a helper method that you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from matplotlib import cm\n",
    "\n",
    "def silhouettes(data, model, n_clusters):\n",
    "    m = clone(model)                                 # Create copy of the model\n",
    "    m.set_params(n_clusters=n_clusters)              # Setting the numbers of clusters\n",
    "    l_pred = m.fit_predict(data)\n",
    "    coef = silhouette_score(data, l_pred)            # Get the silhouette coefficient\n",
    "    print(f\"Silhouette coefficient for {n_clusters}: {np.round(coef, 6)}\")\n",
    "    values = silhouette_samples(data, l_pred)        # Get the silhouette values\n",
    "    colors = cm.get_cmap(\"rainbow\", n_clusters)      # Getting colors\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    fig.suptitle(f\"Silhouette Analysis with {n_clusters} Clusters\")\n",
    "    margin = 10\n",
    "    y_bottom = margin\n",
    "    # Plotting the silhouette values\n",
    "    for c in range(n_clusters):\n",
    "        values_c = values[l_pred == c]               # Just getting values of cluster c\n",
    "        values_c = np.sort(values_c)                 # Sorting the values\n",
    "        size_c = len(values_c)                       # Getting the number of values\n",
    "        y_top = y_bottom + size_c                    # Calculating the value on the y-axis to draw to\n",
    "        color = colors(c/n_clusters)                 # Selecting the color of the cluster\n",
    "        # Plotting the values\n",
    "        (ax.fill_betweenx(                           # Fill an area\n",
    "            np.arange(y_bottom, y_top),              # Range on y-axis to fill\n",
    "            0,                                       # Start value on x-axis\n",
    "            values_c,                                # End value on x-axis\n",
    "            fc=color, ec=color, alpha=.7))           # Some styling\n",
    "        # Plotting the cluster number to the left\n",
    "        ax.text(-.05, y_bottom + .5 * size_c, str(c))\n",
    "        y_bottom = y_top + margin                    # Calculating the next start value on the y-axis\n",
    "    ax.axvline(coef, c=\"k\", ls=\"--\")              # Plotting a vertical line for the silhouette coefficient\n",
    "    ax.set(title=\"Silhouette Values\", xlabel=\"Silhouette Values\", ylabel=\"Clusters\", yticks=[], xlim=(-.1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the dataset from **Ex13_01_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset without the `label` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we only have 2 clusters in the data.\n",
    "Run a k-Means clustering algorithm and calculate the silhouette coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the silhouette coefficient when assuming 5 clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average silhouette value of each of those 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the silhouette coefficients for k-Means with 2 - 10 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the helper method `silhouettes(data, model, n_clusters)` to plot clusters 2 - 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the correct number of clusters?\n",
    "Run a cluster analysis with the number of clusters you think are in the dataset and create a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!\n",
    "You run a simple silhouette analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex13_01_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02 - Density Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to use some advanced plotting methods.\n",
    "To use them, you need some data.\n",
    "Thus, load **Ex13_02_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should already know this dataset.\n",
    "It's the same you used in the last exercise for preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a broad overview how the data is distributed, let's do a `pairplot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some data is correlated.\n",
    "Maybe if we throw in some color, we get a better idea.\n",
    "Use the `cylinders` for coloring the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the `kdeplot()` method and show the density when comparing `horsepower` and `mpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `kdeplot()` method again, but this time for `acceleration` and `weight`.\n",
    "And plot the points as well.\n",
    "Use the `cylinders` for coloring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `jointplot()` method to shoe a comparison of `weight` and `acceleration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same, but this time use  `kind=kde`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `jointplot()` method with `kind=hex` to show a comparison between `displacement` and `horsepower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!\n",
    "You now know some more awesome methods to plot visualize your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex13_02_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex03 - DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you run a DBSCAN algorithm for a given dataset.\n",
    "Load **Ex13_03_Data.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the DBSCAN algorithm and predict the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dataset with the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all the outliers have a color.\n",
    "Plot the clusters, but this time the outliers should be plotted in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the inner and outer circles are always considered as one cluster.\n",
    "Reduce the `eps` to `.1` to get better results and plot the clusters again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!\n",
    "You've successfully applied the DBSCAN clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex13_03_Sol.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
