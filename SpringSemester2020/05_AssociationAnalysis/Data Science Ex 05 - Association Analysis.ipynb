{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Ex 05 - Association Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.03.2020, Lukas Kretschmar (lukas.kretschmar@hsr.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's have some Fun with Market Basket Analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you are going to build and find frequent item sets.\n",
    "And define rules which products are entangled with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've learned, data for the market basket analysis must be in a specific structure.\n",
    "If not, you need to restructure it (see the end of the introduction).\n",
    "\n",
    "For the introduction, let's assume that we already have data in the format we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mba = pd.read_csv(\"./Demo_MarketBasket.csv\")\n",
    "print(f\"Number of receipts: {len(mba)}\")\n",
    "mba.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The needed algorithms are part of the *mlxtend* module.\n",
    "With the following lines, we just import the algorithms that we need to do our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anaconde does not contain the *mlextend* module by default and you have to download it with the following command in the `conda-prompt`.\n",
    "\n",
    "```\n",
    "conda install -c conda-forge mlxtend\n",
    "```\n",
    "\n",
    "And then you can import the methods from the module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating FI Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build our frequent item sets by calling the `apriori()` algorithm that we imported in the line above.\n",
    "Some of the parameters offered by the algorithm are listed below.\n",
    "There are some more, but not relevant for us.\n",
    "All are optional besides the first one - we need data, obviously:\n",
    "- `df` : `DataFrame` containing the data\n",
    "- `min_support` (default: 0.5) : Minimal support the items have to fulfill to be included in the result\n",
    "- `use_colnames` (default: False) : Column names are used instead of their indices in the item sets\n",
    "- `max_len` (default: None) : Maximum number of itemsets returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_sets = apriori(mba, min_support=.05, use_colnames=True)\n",
    "fi_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having our frequent item sets, we can now build the association rules.\n",
    "The `associatin_rules()` method offers the following parameters:\n",
    "- `df` : `DataFrame` containing the frequent item sets\n",
    "- `metric` (default: `\"confidence\"`) : Metric used to define if a rule is interesting. Possible values are:\n",
    "    - `\"support\"`\n",
    "    - `\"confidence\"`\n",
    "    - `\"lift\"`\n",
    "    - `\"leverage\"`\n",
    "    - `\"conviction\"`\n",
    "- `min_threshold` (default: 0.8) : Threashold the metric has to exceed to be considered interesting\n",
    "- `support_only` (default: False) : Only computes support, and sets `metric` to \"support\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(fi_sets, metric=\"confidence\", min_threshold=.2)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `antecedents` column we find the left side of the rule (what was bought) and the `consequents` column contains the right side (what was also bought).\n",
    "And since the rules are a `DataFrame`, we can filter, group and visualize the data with the techniques introduced in the last couple of weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules[(rules[\"confidence\"] >= .3) & (rules[\"lift\"] >= 1.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that milk was bought together with vegetables or yogurt more likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is using visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots() # We need this call, otherwiese the x-ticks won't show up (it's a bug in matplotlib -> https://github.com/pandas-dev/pandas/issues/10611)\n",
    "rules.plot.scatter(ax=ax, x=\"confidence\", y=\"lift\", c=\"support\", cmap=\"rainbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end, it's up to the data scientist to read and interpret the data properly, since domain-knowledge is a vital part of the analysing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nice2Know: Restructuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While researching this topic, I noticed that there is no information available how you can preprocess your data to fit the algorithms needs.\n",
    "Since preprocessing steps highly depend on the given data, it's no surprise there is no single one way to do so.\n",
    "\n",
    "But I included here a step by step approach how you can change the data structure usually found to a format the `apriori()` algorithm can work with.\n",
    "The problem with this algorithm is, that it expects data in a specific format.\n",
    "And usually, data is available in a format like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carts = pd.read_csv(\"./Demo_Groceries_Unstructured.csv\")\n",
    "carts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have a row per shopping cart/receipt.\n",
    "But as a result, we have many missing entries since the number of columns need to cover the largest cart.\n",
    "And the given structure is not suitable for the algorithm.\n",
    "Thus, we have to restructure the data so it can be used by the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Let's get rid of the *Item(s)* column, since we do not need it.\n",
    "But we store its content to validate our new structure at the end.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldSums = carts[\"Item(s)\"]\n",
    "carts = carts.drop(\"Item(s)\", axis=1)\n",
    "carts.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Then we stack our data.\n",
    "As a result, we get a multi-index series containing every carts item in a column.\n",
    "We do this step to get rid of all the `NaN` entries in the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedCarts = carts.stack()\n",
    "stackedCarts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **By reseting the index, we get back a `DataFrame` containing the cart (level_0) and item (0).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedCarts = stackedCarts.reset_index()\n",
    "stackedCarts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **To introduce some readability, we change the column names and drop the obsolete column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedCarts = stackedCarts.rename(columns={\"level_0\" : \"Cart\", 0 : \"Item\"}).drop(\"level_1\",axis=1)\n",
    "stackedCarts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you already get data in a format like shown above.\n",
    "So, the steps before are not necessary while preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **We now add a new column, indicating that an item is in a cart.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note:** This step is only necessary when there is no amount information available.\n",
    "Depending on the dataset you have, it's possible that there is already an amount asigned per item.\n",
    "And then you don't need to add the numbers by yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedCarts[\"Amount\"] = 1\n",
    "stackedCarts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Now we create groups by *Cart* and *Item*, select the *Amount* and sum it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCarts = stackedCarts.groupby([\"Cart\", \"Item\"])[\"Amount\"].sum()\n",
    "newCarts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure has quite a resemblance to the structure we had after step 2 where we stacked the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **We now basically do the reverse by unstacking our new data structure.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCarts = newCarts.unstack()\n",
    "newCarts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **We just have to replace the missing values with 0.\n",
    "And we can change the type to *int*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FYI:** Sometimes the information indicating that an item was present is greater than 1.\n",
    "In this case, you simply change the type first to `bool` and then to `int`.\n",
    "Enforcing `bool` will assign `True` to every value other than `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCarts = newCarts.fillna(0).astype(bool).astype(int)\n",
    "newCarts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's about it.\n",
    "\n",
    "We now just have to check that our values are still matching the original data.\n",
    "An easy check is the number of items per cart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newSums = newCarts.sum(axis=1)\n",
    "newSums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(newSums - oldSums).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`False` indicates that there are no differences.\n",
    "For us, this is a good enough indicator that we didn't change the information contained in the data at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01 - Apriori on a simple Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file **Ex05_01_Data.csv** and list the first 5 lines.\n",
    "You may have to specify the separator `sep` used to get a correct `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should already be familiar with this data.\n",
    "But as you can see, some values are missing and there are `X` instead of `1`.\n",
    "Correct this and show the first 5 lines again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the frequent items set with a `min_support >= .3`.\n",
    "And show the whole itemset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the rules that have a `confidence >= .85` and list them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex05_01_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02 - Apriori on a large Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file **Ex05_02_Data.csv** and list the first couple of lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many shopping carts are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequent item sets with a `min_support >= .3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the rules with `confidence >= .5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rules did you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the rules by their `lift` with the most promising rule on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex05_02_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex03 - Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the file **Ex05_03_Data.csv** and show the first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data is not structured the way we need it to run the apriori algorithm.\n",
    "It's now your job to process the data.\n",
    "The goal is that you can use the result of this exercise as the input of the next one (don't worry, the next exercise comes with it's own input data if you cannot accomplish this one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the data is structured like **Step 5** in the introduction.\n",
    "Thus, you can go on with **Steps 6 - 8**.\n",
    "But compared to the intro, you now have also to include the *Country* into the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the example in the introduction, we have here a multi-index.\n",
    "But that shouldn't bother us.\n",
    "It's actually quite useful when filtering for one country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can store your `DataFrame` with `to_csv(filename)`[(Reference)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) and reload the file in the next exercise.\n",
    "If you save your data, it could be handy to replace every `0` with `np.nan` again or just don't do *Step 8*.\n",
    "This way, the output file needs 50% less storage capacity.\n",
    "\n",
    "Or you can simple reuse the variable containing your `DataFrme` in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for storing file comes here - if you want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex05_03_Sol.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex04 - Apriori on your Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that you use the processed data from the previous exercise.\n",
    "If you were not able to complete the preprocessing, you can use **Ex05_04_Data.csv**.\n",
    "This file contains the same data that you would have gotten from the preprocessing exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you start this exercise from a file (the provided one or the one you created in the previous exercise), you need to do the following steps (otherwise, you can skip these steps):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Set *Country* and *InvoiceNo* as index with `set_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fill the missing data (basically do step 8 from the introdcution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From here, the exercise is the same - for those starting from a file or taking the variable from the exercise above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will have a look at the information from *Switzerland*.\n",
    "Thus, just select the invoices from `Switzerland` by using `df.loc[\"Switzerland\"]` (`df` stands for your variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many invocies are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the frequent item sets with a `min_support >= .1`.\n",
    "And show all the rules with a `confidence >= .7` and order them by their `lift` (best on top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rules did you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these retail information are from a UK based online store, there are much more invoivces from the UK.\n",
    "So get them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many invoices from the UK are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find the frequent item sets (use the same parameters from above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any frequent item sets? - Usually, the larger you datasets are, the lower you have to set the support threshold to even get results.\n",
    "Thus, lower the `min_support` to `.03` and build the rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we surprised that these rules were found?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./Ex05_04_Sol.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
